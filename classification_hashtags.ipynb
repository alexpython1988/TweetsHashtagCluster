{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets classification by its hashtags and no labeled tweets hashtag predication\n",
    "\n",
    "\n",
    "**Using top n hashtags as label to build a supervised model for tweets classification and hashtag predication**\n",
    "\n",
    "[1.1 load data](1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1.1'> load packages and modeling data </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12547262523055465833\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow backend\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "print(keras.__version__)\n",
    "print(keras.backend.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bcolz\n",
    "import pickle\n",
    "\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "    \n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "def save_dict(fname, dictionary):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(dictionary, f)\n",
    "\n",
    "def load_dict(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtag_label': [1, 5],\n",
       " 'hashtags': ['hpv', 'vaccin'],\n",
       " 'id': '418263863772327936',\n",
       " 'orignal_hashtags': ['#hpv', '#vaccine'],\n",
       " 'raw': 'rt @cdcstd: #hpv vax coverage could be 93% if doctors gave hpv #vaccine each time a preteen/teen got any other vaccine&gt; http://t.co/xxryga5â€¦',\n",
       " 'text': 'rt : hpv vax coverage could be 93% if doctors gave hpv vaccine each time a preteen / teen got any other vaccine>',\n",
       " 'words': ['rt',\n",
       "  ':',\n",
       "  'hpv',\n",
       "  'vax',\n",
       "  'coverage',\n",
       "  'could',\n",
       "  'be',\n",
       "  '93',\n",
       "  '%',\n",
       "  'if',\n",
       "  'doctors',\n",
       "  'gave',\n",
       "  'hpv',\n",
       "  'vaccine',\n",
       "  'each',\n",
       "  'time',\n",
       "  'a',\n",
       "  'preteen',\n",
       "  '/',\n",
       "  'teen',\n",
       "  'got',\n",
       "  'any',\n",
       "  'other',\n",
       "  'vaccine',\n",
       "  '>']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load tweets data\n",
    "import json\n",
    "tweets_file = \"temp/tweets4classification.json\"\n",
    "with open(tweets_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    modeling_data = json.load(f)\n",
    "modeling_data['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load processed word enbeddings\n",
    "path = 'wordsenbeddings/'\n",
    "res_path = path + 'results/'\n",
    "\n",
    "def load_vectors(name):\n",
    "    loc = res_path + name\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_glove(name, dim):\n",
    "    with open(path+ 'glove.' + name + '.txt', 'r', encoding=\"utf-8\") as f:\n",
    "        vecs = []\n",
    "        words = []\n",
    "        \n",
    "        for i, line in enumerate(f):\n",
    "            d = line.split()\n",
    "            word = d[0]\n",
    "            vec = np.array(d[1:], dtype=np.float32)\n",
    "            if (len(d) == dim): # this is space\n",
    "                word = ' '\n",
    "                vec = np.array(d, dtype=np.float32)\n",
    "            \n",
    "            words.append(word)            \n",
    "            vecs.append(vec)\n",
    "\n",
    "        wordidx = {o:i for i,o in enumerate(words)}\n",
    "        save_array(res_path+name+'.dat', vecs)\n",
    "        pickle.dump(words, open(res_path+name+'_words.pkl','wb'))\n",
    "        pickle.dump(wordidx, open(res_path+name+'_idx.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_glove('twitter.27B.200d', 200)\n",
    "get_glove('twitter.27B.25d', 25)\n",
    "get_glove('twitter.27B.50d', 50)\n",
    "get_glove('twitter.27B.100d', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare train and test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ list(['rt', ':', 'hpv', 'vax', 'coverage', 'could', 'be', '93', '%', 'if', 'doctors', 'gave', 'hpv', 'vaccine', 'each', 'time', 'a', 'preteen', '/', 'teen', 'got', 'any', 'other', 'vaccine', '>'])\n",
      " list(['rt', ':', 'hpv', 'vax', 'coverage', 'could', 'be', '93', '%', 'if', 'doctors', 'gave', 'hpv', 'vaccine', 'each', 'time', 'a', 'preteen', '/', 'teen', 'got', 'any', 'other', 'vaccine', '...', '.'])]\n",
      "[list([1, 5]) list([1, 5])]\n",
      "81049\n",
      "81049\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray([each['words'] for each in modeling_data['data']])\n",
    "label = np.asarray([each['hashtag_label'] for each in modeling_data['data']])\n",
    "\n",
    "print(data[:2])\n",
    "print(label[:2])\n",
    "print(len(data))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flat_labels(labels):\n",
    "    flatted = []\n",
    "    l = modeling_data['categorical_num']\n",
    "    for label in labels:\n",
    "        m = [0.] * l\n",
    "        for each in label:\n",
    "            m = list(map(lambda x: x[0] + x[1], zip(m, each)))\n",
    "        flatted.append(m)\n",
    "    return np.asarray(flatted)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "categorical_label = list(map(lambda x: to_categorical(x, num_classes=modeling_data['categorical_num']), label))\n",
    "\n",
    "categorical_label_flatted = flat_labels(categorical_label)\n",
    "\n",
    "print(len(categorical_label))\n",
    "categorical_label_flatted[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_0, X_test, y_train_0, y_test = train_test_split(data, categorical_label_flatted, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ list(['rt', ':', 'new', 'infographic', 'on', 'how', 'most', 'cases', 'of', 'cervicalcancer', 'can', 'be', 'prevented', 'w', '/', 'tests', '&', 'hpv', 'vaccine', '.', 'vitalsigns'])\n",
      " list(['check', 'out', 'the', 'gci', 'team', \"'s\", 'newest', 'publication', 'on', 'hpv', 'vaccine', 'implementation', 'for', 'cancer', 'prevention', 'in', 'latinamerica', '!'])]\n",
      "[ list(['two', 'uk', 'girls', 'left', 'paralyzed', 'after', 'hpv', 'jabs', '.', 'authorities', 'still', 'claim', 'it', \"'s\", 'coincidence', '.'])\n",
      " list(['cervicalcancer', 'deaths', 'have', 'decreased', 'dramatically', 'over', 'the', 'past', '40', 'years', ',', 'mostly', 'due', 'to', 'increased', 'screening', '.'])]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_0[:2])\n",
    "print(X_test[:2])\n",
    "print(y_train_0[:2])\n",
    "print(y_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save 5% train samples to predication task\n",
    "cut = int(len(X_train_0) * 0.95)\n",
    "X_train = X_train_0[:cut]\n",
    "y_train = y_train_0[:cut]\n",
    "X_pred = X_train_0[cut:]\n",
    "y_pred = y_train_0[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-8b9e755e8c1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mall_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'words'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeling_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-8b9e755e8c1c>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mall_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'words'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeling_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!!!!!do not run this, run the third one below this to directly load the dictionary\n",
    "#create words dictionary for the data\n",
    "from functools import reduce\n",
    "\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "\n",
    "all_tokens = list(reduce(lambda x, y: x + y, [l['words'] for l in modeling_data['data']]))\n",
    "print(all_tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(all_tokens))\n",
    "\n",
    "for token in all_tokens:\n",
    "    frequency[token] += 1\n",
    "    \n",
    "dictionary = sorted(frequency.items(), key=lambda x:x[1], reverse=True)\n",
    "dictionary = [k for k,v in dictionary[:vocab_size]]\n",
    "print(dictionary[:10])\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dict('model/dict.dd', dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':',\n",
       " 'hpv',\n",
       " 'rt',\n",
       " 'vaccine',\n",
       " '.',\n",
       " 'the',\n",
       " ',',\n",
       " 'of',\n",
       " 'to',\n",
       " 'cancer',\n",
       " 'in',\n",
       " 'gardasil',\n",
       " 'for',\n",
       " 'cervicalcancer',\n",
       " 'a',\n",
       " '&',\n",
       " 'and',\n",
       " 'is',\n",
       " '!',\n",
       " 'cervical']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 0\n",
    "dictionary = load_dict('model/dict.dd')\n",
    "if (not vocab_size):\n",
    "    vocab_size = len(dictionary)\n",
    "dictionary[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word to index\n",
    "X_train_f = [[dictionary.index(word) if word in dictionary else -1 for word in doc] for doc in X_train]\n",
    "X_test_f = [[dictionary.index(word) if word in dictionary else -1 for word in doc] for doc in X_test]\n",
    "X_pred_f = [[dictionary.index(word) if word in dictionary else -1 for word in doc] for doc in X_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 0, 46, 781, 22, 74, 100, 121, 7, 13, 35, 55, 352, 54, 40, 162, 15, 1, 3, 4, 1126], [364, 93, 5, 10430, 1019, 20, 1770, 3765, 22, 1, 3, 1637, 12, 9, 61, 10, 8726, 18], [1159, 49, 251, 22, 97, 4382, 12, 448, 3863, 8, 20, 1, 25, 493, 18, 400, 13], [2, 0, 122, 312, 90, 662, 57, 8, 369, 33, 13, 4, 529, 26, 967, 16, 1777, 831, 8, 39, 365, 12, 1], [2, 0, 27, 0, 11, 131, 19, 328, 10, 31, 244, 54, 40, 1, 51]]\n",
      "[[210, 338, 41, 215, 165, 34, 1, 471, 4, 459, 182, 409, 29, 20, 411, 4], [13, 180, 57, 1813, 2238, 296, 5, 1477, 1003, 134, 6, 3875, 616, 8, 448, 67, 4], [2, 0, 27, 0, 14, 262, 7, 346, 362, 10, 14, 509, 110, 118, 250, 34, 168, 1, 3], [726, 12, 8803, 423, 23, 155, 15, 281, 223, 397, 8, 1, 0, 492, 287], [97, 1, 16, 9, 153, 2965, 3326, 3551, 22, 2585, 193, 18, 1077, 125, 8, 159, 0]]\n",
      "[[3, 1413, 264, 41, 177, 1, 68, 32, 757, 37, 697], [2, 0, 4, 84, 981, 18, 11, 3379, 6, 226, 2928, 10352, 1760, 81, 10353, 6, 4817, 19993, 4], [2, 0, 30, 24, 478, 11, 11792, 21], [1, 25, 68, 569, 145, 917, 41, 10, 2948, 1620, 45], [2, 0, 1026, 0, 2602, 1592, 16, 1282, 4158, 7, 19, 9, 422, 33, 1780]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_f[:5])\n",
    "print(X_test_f[:5])\n",
    "print(X_pred_f[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding words using GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 2, 17.012127213987693)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = np.array([len(doc) for doc in X_train_f])\n",
    "(lens.max(), lens.min(), lens.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 39\n",
    "embedding_dim = 50\n",
    "vecs, words, wordidx = load_vectors('twitter.27B.%dd'%(embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_u = sequence.pad_sequences(X_train_f, maxlen=seq_len)\n",
    "X_test_u = sequence.pad_sequences(X_test_f, maxlen=seq_len)\n",
    "X_pred_u = sequence.pad_sequences(X_pred_f, maxlen=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     2     0    46   781    22    74\n",
      "    100   121     7    13    35    55   352    54    40   162    15     1\n",
      "      3     4  1126]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0   364    93     5\n",
      "  10430  1019    20  1770  3765    22     1     3  1637    12     9    61\n",
      "     10  8726    18]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0  1159    49\n",
      "    251    22    97  4382    12   448  3863     8    20     1    25   493\n",
      "     18   400    13]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     2     0   122   312    90   662    57     8\n",
      "    369    33    13     4   529    26   967    16  1777   831     8    39\n",
      "    365    12     1]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      2     0    27     0    11   131    19   328    10    31   244    54\n",
      "     40     1    51]]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0  210  338   41  215  165\n",
      "    34    1  471    4  459  182  409   29   20  411    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   13  180   57 1813 2238  296\n",
      "     5 1477 1003  134    6 3875  616    8  448   67    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    2    0   27    0   14  262    7  346\n",
      "   362   10   14  509  110  118  250   34  168    1    3]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0  726   12 8803  423\n",
      "    23  155   15  281  223  397    8    1    0  492  287]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   97    1   16    9  153 2965\n",
      "  3326 3551   22 2585  193   18 1077  125    8  159    0]]\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     3  1413   264    41   177     1    68    32\n",
      "    757    37   697]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     2     0     4    84\n",
      "    981    18    11  3379     6   226  2928 10352  1760    81 10353     6\n",
      "   4817 19993     4]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     2     0    30    24   478\n",
      "     11 11792    21]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     1    25    68   569   145   917    41    10\n",
      "   2948  1620    45]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      2     0  1026     0  2602  1592    16  1282  4158     7    19     9\n",
      "    422    33  1780]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_u[:5])\n",
    "print(X_test_u[:5])\n",
    "print(X_pred_u[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_embedding(dictionary):\n",
    "    print(vecs.shape)\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "\n",
    "    for i, word in enumerate(dictionary):\n",
    "        #if word:# and re.match(r\"^[a-zA-Z0-9\\-]*$\", word):\n",
    "        src_idx = wordidx[word] if word in wordidx else 0\n",
    "        \n",
    "        if src_idx:\n",
    "            emb[i] = vecs[src_idx]\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "    emb/=3\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1193517, 50)\n"
     ]
    }
   ],
   "source": [
    "embedding = create_embedding(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create CNN mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 39, 50)            1165350   \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 39, 50)            10050     \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 39, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 39, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 39, 50)            10050     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 39, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 39, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 39, 50)            10050     \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 39, 50)            10050     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 39, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1950)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 11)                21461     \n",
      "=================================================================\n",
      "Total params: 1,247,111\n",
      "Trainable params: 81,761\n",
      "Non-trainable params: 1,165,350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dth = 0.4\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=seq_len, weights=[embedding], trainable=False))\n",
    "# model.add(Dropout(dth))\n",
    "\n",
    "#hidden layer\n",
    "model.add(Conv1D(embedding_dim, 4, padding='same', activation='relu'))\n",
    "model.add(Conv1D(embedding_dim, 4, padding='same', activation='relu'))\n",
    "model.add(Dropout(dth))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(embedding_dim, 4, padding='same', activation='relu'))\n",
    "model.add(Conv1D(embedding_dim, 4, padding='same', activation='relu'))\n",
    "model.add(Dropout(dth))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# crf = ChainCRF()\n",
    "# model.add(crf)\n",
    "model.add(Conv1D(embedding_dim, 4, padding='same', activation='relu'))\n",
    "model.add(Conv1D(embedding_dim, 4, padding='same', activation='relu'))\n",
    "model.add(Dropout(dth))\n",
    "\n",
    "#output layer\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(dth))\n",
    "model.add(Dense(modeling_data['categorical_num'], activation='sigmoid'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "#also can use SDG as optimizer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-4\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model_chk_path = 'model/cnn_hashtagcls_emb{}_weights.validation.h5'.format(embedding_dim)\n",
    "mcp = ModelCheckpoint(model_chk_path, monitor=\"val_loss\", verbose=1,\n",
    "                      save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61597 samples, validate on 16210 samples\n",
      "Epoch 1/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 2.8189 - acc: 0.6226 - val_loss: 2.4061 - val_acc: 0.6459\n",
      "Epoch 2/100\n",
      "61597/61597 [==============================] - 103s 2ms/step - loss: 2.2315 - acc: 0.7048 - val_loss: 2.0340 - val_acc: 0.7228\n",
      "Epoch 3/100\n",
      "61597/61597 [==============================] - 108s 2ms/step - loss: 2.0148 - acc: 0.7292 - val_loss: 1.8737 - val_acc: 0.7172\n",
      "Epoch 4/100\n",
      "61597/61597 [==============================] - 107s 2ms/step - loss: 1.8780 - acc: 0.7262 - val_loss: 1.7382 - val_acc: 0.7285\n",
      "Epoch 5/100\n",
      "61597/61597 [==============================] - 107s 2ms/step - loss: 1.7810 - acc: 0.7309 - val_loss: 1.6658 - val_acc: 0.7368\n",
      "Epoch 6/100\n",
      "61597/61597 [==============================] - 110s 2ms/step - loss: 1.7006 - acc: 0.7371 - val_loss: 1.5770 - val_acc: 0.7250\n",
      "Epoch 7/100\n",
      "61597/61597 [==============================] - 109s 2ms/step - loss: 1.6419 - acc: 0.7405 - val_loss: 1.5321 - val_acc: 0.7297\n",
      "Epoch 8/100\n",
      "61597/61597 [==============================] - 109s 2ms/step - loss: 1.5989 - acc: 0.7459 - val_loss: 1.5064 - val_acc: 0.7263\n",
      "Epoch 9/100\n",
      "61597/61597 [==============================] - 109s 2ms/step - loss: 1.5673 - acc: 0.7488 - val_loss: 1.4791 - val_acc: 0.7341\n",
      "Epoch 10/100\n",
      "61597/61597 [==============================] - 108s 2ms/step - loss: 1.5376 - acc: 0.7540 - val_loss: 1.4649 - val_acc: 0.7450\n",
      "Epoch 11/100\n",
      "61597/61597 [==============================] - 109s 2ms/step - loss: 1.5136 - acc: 0.7596 - val_loss: 1.4417 - val_acc: 0.7585\n",
      "Epoch 12/100\n",
      "61597/61597 [==============================] - 112s 2ms/step - loss: 1.4944 - acc: 0.7611 - val_loss: 1.4275 - val_acc: 0.7674\n",
      "Epoch 13/100\n",
      "61597/61597 [==============================] - 110s 2ms/step - loss: 1.4755 - acc: 0.7646 - val_loss: 1.4138 - val_acc: 0.7472\n",
      "Epoch 14/100\n",
      "61597/61597 [==============================] - 110s 2ms/step - loss: 1.4570 - acc: 0.7669 - val_loss: 1.3986 - val_acc: 0.7616\n",
      "Epoch 15/100\n",
      "61597/61597 [==============================] - 110s 2ms/step - loss: 1.4408 - acc: 0.7705 - val_loss: 1.3862 - val_acc: 0.7626\n",
      "Epoch 16/100\n",
      "61597/61597 [==============================] - 111s 2ms/step - loss: 1.4284 - acc: 0.7744 - val_loss: 1.3802 - val_acc: 0.7638\n",
      "Epoch 17/100\n",
      "61597/61597 [==============================] - 110s 2ms/step - loss: 1.4148 - acc: 0.7754 - val_loss: 1.3655 - val_acc: 0.7724\n",
      "Epoch 18/100\n",
      "61597/61597 [==============================] - 109s 2ms/step - loss: 1.4022 - acc: 0.7779 - val_loss: 1.3591 - val_acc: 0.7529\n",
      "Epoch 19/100\n",
      "61597/61597 [==============================] - 110s 2ms/step - loss: 1.3927 - acc: 0.7787 - val_loss: 1.3505 - val_acc: 0.7765\n",
      "Epoch 20/100\n",
      "61597/61597 [==============================] - 110s 2ms/step - loss: 1.3800 - acc: 0.7832 - val_loss: 1.3419 - val_acc: 0.7724\n",
      "Epoch 21/100\n",
      "61597/61597 [==============================] - 109s 2ms/step - loss: 1.3709 - acc: 0.7887 - val_loss: 1.3393 - val_acc: 0.7954\n",
      "Epoch 22/100\n",
      "61597/61597 [==============================] - 109s 2ms/step - loss: 1.3628 - acc: 0.7882 - val_loss: 1.3187 - val_acc: 0.7803\n",
      "Epoch 23/100\n",
      "61597/61597 [==============================] - 109s 2ms/step - loss: 1.3529 - acc: 0.7906 - val_loss: 1.3162 - val_acc: 0.7846\n",
      "Epoch 24/100\n",
      "61597/61597 [==============================] - 108s 2ms/step - loss: 1.3432 - acc: 0.7924 - val_loss: 1.3068 - val_acc: 0.7993\n",
      "Epoch 25/100\n",
      "61597/61597 [==============================] - 108s 2ms/step - loss: 1.3337 - acc: 0.7959 - val_loss: 1.3036 - val_acc: 0.7770\n",
      "Epoch 26/100\n",
      "61597/61597 [==============================] - 100s 2ms/step - loss: 1.3256 - acc: 0.7925 - val_loss: 1.2945 - val_acc: 0.8075\n",
      "Epoch 27/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.3205 - acc: 0.7957 - val_loss: 1.2912 - val_acc: 0.8019\n",
      "Epoch 28/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.3143 - acc: 0.7977 - val_loss: 1.2866 - val_acc: 0.8027\n",
      "Epoch 29/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.3077 - acc: 0.7983 - val_loss: 1.2850 - val_acc: 0.8039\n",
      "Epoch 30/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.3005 - acc: 0.7985 - val_loss: 1.2743 - val_acc: 0.8065\n",
      "Epoch 31/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2961 - acc: 0.7987 - val_loss: 1.2756 - val_acc: 0.7911\n",
      "Epoch 32/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2885 - acc: 0.8010 - val_loss: 1.2652 - val_acc: 0.7872\n",
      "Epoch 33/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2838 - acc: 0.8031 - val_loss: 1.2670 - val_acc: 0.8100\n",
      "Epoch 34/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2805 - acc: 0.8023 - val_loss: 1.2580 - val_acc: 0.7924\n",
      "Epoch 35/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2750 - acc: 0.8020 - val_loss: 1.2588 - val_acc: 0.8138\n",
      "Epoch 36/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2702 - acc: 0.8031 - val_loss: 1.2550 - val_acc: 0.7911\n",
      "Epoch 37/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2667 - acc: 0.8029 - val_loss: 1.2470 - val_acc: 0.7965\n",
      "Epoch 38/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2605 - acc: 0.8092 - val_loss: 1.2454 - val_acc: 0.8028\n",
      "Epoch 39/100\n",
      "61597/61597 [==============================] - 101s 2ms/step - loss: 1.2591 - acc: 0.8051 - val_loss: 1.2415 - val_acc: 0.7936\n",
      "Epoch 40/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2556 - acc: 0.8091 - val_loss: 1.2462 - val_acc: 0.8076\n",
      "Epoch 41/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2496 - acc: 0.8055 - val_loss: 1.2396 - val_acc: 0.7970\n",
      "Epoch 42/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2478 - acc: 0.8056 - val_loss: 1.2354 - val_acc: 0.7971\n",
      "Epoch 43/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2452 - acc: 0.8073 - val_loss: 1.2356 - val_acc: 0.8089\n",
      "Epoch 44/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2425 - acc: 0.8078 - val_loss: 1.2359 - val_acc: 0.8236\n",
      "Epoch 45/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2392 - acc: 0.8074 - val_loss: 1.2301 - val_acc: 0.8208\n",
      "Epoch 46/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.2365 - acc: 0.8101 - val_loss: 1.2247 - val_acc: 0.8115\n",
      "Epoch 47/100\n",
      "61597/61597 [==============================] - 100s 2ms/step - loss: 1.2327 - acc: 0.8126 - val_loss: 1.2277 - val_acc: 0.7948\n",
      "Epoch 48/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2313 - acc: 0.8097 - val_loss: 1.2255 - val_acc: 0.8025\n",
      "Epoch 49/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.2301 - acc: 0.8096 - val_loss: 1.2218 - val_acc: 0.7941\n",
      "Epoch 50/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2249 - acc: 0.8097 - val_loss: 1.2209 - val_acc: 0.7969\n",
      "Epoch 51/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.2217 - acc: 0.8110 - val_loss: 1.2205 - val_acc: 0.8021\n",
      "Epoch 52/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.2214 - acc: 0.8128 - val_loss: 1.2232 - val_acc: 0.8336\n",
      "Epoch 53/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2202 - acc: 0.8091 - val_loss: 1.2211 - val_acc: 0.8186\n",
      "Epoch 54/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2157 - acc: 0.8095 - val_loss: 1.2167 - val_acc: 0.7945\n",
      "Epoch 55/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2151 - acc: 0.8130 - val_loss: 1.2144 - val_acc: 0.7949\n",
      "Epoch 56/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2117 - acc: 0.8086 - val_loss: 1.2146 - val_acc: 0.7958\n",
      "Epoch 57/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.2083 - acc: 0.8111 - val_loss: 1.2107 - val_acc: 0.7959\n",
      "Epoch 58/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2071 - acc: 0.8117 - val_loss: 1.2157 - val_acc: 0.7975\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.2049 - acc: 0.8117 - val_loss: 1.2101 - val_acc: 0.7895\n",
      "Epoch 60/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.2031 - acc: 0.8124 - val_loss: 1.2089 - val_acc: 0.7932\n",
      "Epoch 61/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.2006 - acc: 0.8151 - val_loss: 1.2094 - val_acc: 0.8067\n",
      "Epoch 62/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.2006 - acc: 0.8137 - val_loss: 1.2062 - val_acc: 0.8032\n",
      "Epoch 63/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1988 - acc: 0.8140 - val_loss: 1.2076 - val_acc: 0.8151\n",
      "Epoch 64/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1989 - acc: 0.8129 - val_loss: 1.2068 - val_acc: 0.8011\n",
      "Epoch 65/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1956 - acc: 0.8130 - val_loss: 1.2074 - val_acc: 0.8027\n",
      "Epoch 66/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1952 - acc: 0.8139 - val_loss: 1.2049 - val_acc: 0.8038\n",
      "Epoch 67/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1928 - acc: 0.8141 - val_loss: 1.2089 - val_acc: 0.8016\n",
      "Epoch 68/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1927 - acc: 0.8112 - val_loss: 1.2021 - val_acc: 0.8065\n",
      "Epoch 69/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1898 - acc: 0.8113 - val_loss: 1.2147 - val_acc: 0.8128\n",
      "Epoch 70/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1901 - acc: 0.8123 - val_loss: 1.2100 - val_acc: 0.8028\n",
      "Epoch 71/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.1880 - acc: 0.8126 - val_loss: 1.2079 - val_acc: 0.7972\n",
      "Epoch 72/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.1856 - acc: 0.8140 - val_loss: 1.1997 - val_acc: 0.8048\n",
      "Epoch 73/100\n",
      "61597/61597 [==============================] - 100s 2ms/step - loss: 1.1854 - acc: 0.8119 - val_loss: 1.2077 - val_acc: 0.7940\n",
      "Epoch 74/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.1835 - acc: 0.8150 - val_loss: 1.2029 - val_acc: 0.8275\n",
      "Epoch 75/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.1803 - acc: 0.8118 - val_loss: 1.1992 - val_acc: 0.8108\n",
      "Epoch 76/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.1816 - acc: 0.8128 - val_loss: 1.2009 - val_acc: 0.8082\n",
      "Epoch 77/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.1819 - acc: 0.8133 - val_loss: 1.1982 - val_acc: 0.8242\n",
      "Epoch 78/100\n",
      "61597/61597 [==============================] - 100s 2ms/step - loss: 1.1792 - acc: 0.8152 - val_loss: 1.1977 - val_acc: 0.8144\n",
      "Epoch 79/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.1791 - acc: 0.8091 - val_loss: 1.1952 - val_acc: 0.80648\n",
      "Epoch 80/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1765 - acc: 0.8147 - val_loss: 1.1936 - val_acc: 0.7904\n",
      "Epoch 81/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1740 - acc: 0.8121 - val_loss: 1.2015 - val_acc: 0.8019\n",
      "Epoch 82/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.1762 - acc: 0.8133 - val_loss: 1.1988 - val_acc: 0.8068\n",
      "Epoch 83/100\n",
      "61597/61597 [==============================] - 100s 2ms/step - loss: 1.1752 - acc: 0.8164 - val_loss: 1.2020 - val_acc: 0.8010\n",
      "Epoch 84/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1721 - acc: 0.8120 - val_loss: 1.1948 - val_acc: 0.8015\n",
      "Epoch 85/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.1713 - acc: 0.8115 - val_loss: 1.1952 - val_acc: 0.8299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d2268b0d68>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick test\n",
    "model.fit(X_train_u, y_train, validation_data=(X_test_u, y_test), epochs=100, batch_size=64,  callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### result\n",
    "- 0.7513\n",
    "- 0.7524\n",
    "- 0.8014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and save model for future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69296 samples, validate on 8105 samples\n",
      "Epoch 1/100\n",
      "69296/69296 [==============================] - 97s - loss: 2.1843 - acc: 0.6984 - val_loss: 1.6926 - val_acc: 0.7502\n",
      "Epoch 2/100\n",
      "69296/69296 [==============================] - 100s - loss: 1.7493 - acc: 0.7348 - val_loss: 1.5139 - val_acc: 0.7563\n",
      "Epoch 3/100\n",
      "69296/69296 [==============================] - 101s - loss: 1.6369 - acc: 0.7431 - val_loss: 1.4294 - val_acc: 0.7542\n",
      "Epoch 4/100\n",
      "69296/69296 [==============================] - 102s - loss: 1.5707 - acc: 0.7438 - val_loss: 1.3870 - val_acc: 0.7717\n",
      "Epoch 5/100\n",
      "69296/69296 [==============================] - 100s - loss: 1.5313 - acc: 0.7456 - val_loss: 1.3586 - val_acc: 0.7671\n",
      "Epoch 6/100\n",
      "69296/69296 [==============================] - 100s - loss: 1.5059 - acc: 0.7419 - val_loss: 1.3368 - val_acc: 0.7651\n",
      "Epoch 7/100\n",
      "69296/69296 [==============================] - 100s - loss: 1.4879 - acc: 0.7399 - val_loss: 1.3289 - val_acc: 0.7520\n",
      "Epoch 8/100\n",
      "69296/69296 [==============================] - 100s - loss: 1.4739 - acc: 0.7427 - val_loss: 1.3175 - val_acc: 0.7571\n",
      "Epoch 9/100\n",
      "69296/69296 [==============================] - 101s - loss: 1.4610 - acc: 0.7436 - val_loss: 1.3055 - val_acc: 0.7431\n",
      "Epoch 10/100\n",
      "69296/69296 [==============================] - 104s - loss: 1.4557 - acc: 0.7458 - val_loss: 1.3065 - val_acc: 0.7440\n",
      "Epoch 11/100\n",
      "69296/69296 [==============================] - 104s - loss: 1.4464 - acc: 0.7429 - val_loss: 1.2919 - val_acc: 0.7420\n",
      "Epoch 12/100\n",
      "69296/69296 [==============================] - 104s - loss: 1.4345 - acc: 0.7423 - val_loss: 1.2962 - val_acc: 0.7356\n",
      "Epoch 13/100\n",
      "69296/69296 [==============================] - 105s - loss: 1.4322 - acc: 0.7425 - val_loss: 1.2909 - val_acc: 0.7384\n",
      "Epoch 14/100\n",
      "69296/69296 [==============================] - 104s - loss: 1.4256 - acc: 0.7448 - val_loss: 1.2823 - val_acc: 0.7499\n",
      "Epoch 15/100\n",
      "69296/69296 [==============================] - 103s - loss: 1.4223 - acc: 0.7429 - val_loss: 1.2795 - val_acc: 0.7571\n",
      "Epoch 16/100\n",
      "69296/69296 [==============================] - 103s - loss: 1.4133 - acc: 0.7406 - val_loss: 1.2808 - val_acc: 0.7489\n",
      "Epoch 17/100\n",
      "69296/69296 [==============================] - 99s - loss: 1.4108 - acc: 0.7405 - val_loss: 1.2779 - val_acc: 0.7373\n",
      "Epoch 18/100\n",
      "69296/69296 [==============================] - 97s - loss: 1.4037 - acc: 0.7455 - val_loss: 1.2724 - val_acc: 0.7403\n",
      "Epoch 19/100\n",
      "69296/69296 [==============================] - 97s - loss: 1.4033 - acc: 0.7433 - val_loss: 1.2681 - val_acc: 0.7578\n",
      "Epoch 20/100\n",
      "69296/69296 [==============================] - 95s - loss: 1.4023 - acc: 0.7451 - val_loss: 1.2666 - val_acc: 0.7469\n",
      "Epoch 21/100\n",
      "69296/69296 [==============================] - 97s - loss: 1.3991 - acc: 0.7425 - val_loss: 1.2674 - val_acc: 0.7542\n",
      "Epoch 22/100\n",
      "69296/69296 [==============================] - 100s - loss: 1.3970 - acc: 0.7457 - val_loss: 1.2634 - val_acc: 0.7388\n",
      "Epoch 23/100\n",
      "21440/69296 [========>.....................] - ETA: 70s - loss: 1.4018 - acc: 0.7443"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-3b88581df02d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1598\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train_u, y_train, validation_data=(X_test_u, y_test), epochs=100, batch_size=64, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=True\n",
    "model.optimizer.lr=1e-3\n",
    "model.fit(X_train_u, y_train, validation_data=(X_test_u, y_test), epochs=100, batch_size=64, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save_weights('model/cnn_hashtagcls_emb{}_weights.h5'.format(embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine train and test data and retrain the model as the final model to use for predication\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "model.fit(\n",
    "    np.concatenate((X_train_u, y_train), axis=0),\n",
    "    np.concatenate((X_test_u, y_test), axis=0),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping])\n",
    "model.save_weights(\n",
    "    \"model/all_cnn_hashtagcls_emb{}_weights.h5\".format(embedding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract the last hidden layer information\n",
    ">https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predication\n",
    "**The predication will be performed on both no_labeled data set and neg_sample**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load two data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
