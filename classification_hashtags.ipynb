{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets classification by its hashtags and no labeled tweets hashtag predication\n",
    "\n",
    "\n",
    "**Using top n hashtags as label to build a supervised model for tweets classification and hashtag predication**\n",
    "\n",
    "[1.1 load data](1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1.1'> load packages and modeling data </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12547262523055465833\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow backend\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "print(keras.__version__)\n",
    "print(keras.backend.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bcolz\n",
    "import pickle\n",
    "\n",
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "    \n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "def save_dict(fname, dictionary):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(dictionary, f)\n",
    "\n",
    "def load_dict(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hashtag_label': [1, 5],\n",
       " 'hashtags': ['hpv', 'vaccin'],\n",
       " 'id': '418263863772327936',\n",
       " 'orignal_hashtags': ['#hpv', '#vaccine'],\n",
       " 'raw': 'rt @cdcstd: #hpv vax coverage could be 93% if doctors gave hpv #vaccine each time a preteen/teen got any other vaccine&gt; http://t.co/xxryga5â€¦',\n",
       " 'text': 'rt : hpv vax coverage could be 93% if doctors gave hpv vaccine each time a preteen / teen got any other vaccine>',\n",
       " 'words': ['rt',\n",
       "  ':',\n",
       "  'hpv',\n",
       "  'vax',\n",
       "  'coverage',\n",
       "  'could',\n",
       "  'be',\n",
       "  '93',\n",
       "  '%',\n",
       "  'if',\n",
       "  'doctors',\n",
       "  'gave',\n",
       "  'hpv',\n",
       "  'vaccine',\n",
       "  'each',\n",
       "  'time',\n",
       "  'a',\n",
       "  'preteen',\n",
       "  '/',\n",
       "  'teen',\n",
       "  'got',\n",
       "  'any',\n",
       "  'other',\n",
       "  'vaccine',\n",
       "  '>']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load tweets data\n",
    "import json\n",
    "tweets_file = \"temp/tweets4classification.json\"\n",
    "with open(tweets_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    modeling_data = json.load(f)\n",
    "modeling_data['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load processed word enbeddings\n",
    "path = 'wordsenbeddings/'\n",
    "res_path = path + 'results/'\n",
    "\n",
    "def load_vectors(name):\n",
    "    loc = res_path + name\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_glove(name, dim):\n",
    "    with open(path+ 'glove.' + name + '.txt', 'r', encoding=\"utf-8\") as f:\n",
    "        vecs = []\n",
    "        words = []\n",
    "        \n",
    "        for i, line in enumerate(f):\n",
    "            d = line.split()\n",
    "            word = d[0]\n",
    "            vec = np.array(d[1:], dtype=np.float32)\n",
    "            if (len(d) == dim): # this is space\n",
    "                word = ' '\n",
    "                vec = np.array(d, dtype=np.float32)\n",
    "            \n",
    "            words.append(word)            \n",
    "            vecs.append(vec)\n",
    "\n",
    "        wordidx = {o:i for i,o in enumerate(words)}\n",
    "        save_array(res_path+name+'.dat', vecs)\n",
    "        pickle.dump(words, open(res_path+name+'_words.pkl','wb'))\n",
    "        pickle.dump(wordidx, open(res_path+name+'_idx.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_glove('twitter.27B.200d', 200)\n",
    "get_glove('twitter.27B.25d', 25)\n",
    "get_glove('twitter.27B.50d', 50)\n",
    "get_glove('twitter.27B.100d', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare train and test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ list(['rt', ':', 'hpv', 'vax', 'coverage', 'could', 'be', '93', '%', 'if', 'doctors', 'gave', 'hpv', 'vaccine', 'each', 'time', 'a', 'preteen', '/', 'teen', 'got', 'any', 'other', 'vaccine', '>'])\n",
      " list(['rt', ':', 'hpv', 'vax', 'coverage', 'could', 'be', '93', '%', 'if', 'doctors', 'gave', 'hpv', 'vaccine', 'each', 'time', 'a', 'preteen', '/', 'teen', 'got', 'any', 'other', 'vaccine', '...', '.'])]\n",
      "[list([1, 5]) list([1, 5])]\n",
      "81049\n",
      "81049\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray([each['words'] for each in modeling_data['data']])\n",
    "label = np.asarray([each['hashtag_label'] for each in modeling_data['data']])\n",
    "\n",
    "print(data[:2])\n",
    "print(label[:2])\n",
    "print(len(data))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flat_labels(labels):\n",
    "    flatted = []\n",
    "    l = modeling_data['categorical_num']\n",
    "    for label in labels:\n",
    "        m = [0.] * l\n",
    "        for each in label:\n",
    "            m = list(map(lambda x: x[0] + x[1], zip(m, each)))\n",
    "        flatted.append(m)\n",
    "    return np.asarray(flatted)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "categorical_label = list(map(lambda x: to_categorical(x, num_classes=modeling_data['categorical_num']), label))\n",
    "\n",
    "categorical_label_flatted = flat_labels(categorical_label)\n",
    "\n",
    "print(len(categorical_label))\n",
    "categorical_label_flatted[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_0, X_test, y_train_0, y_test = train_test_split(data, categorical_label_flatted, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ list(['rt', ':', 'new', 'infographic', 'on', 'how', 'most', 'cases', 'of', 'cervicalcancer', 'can', 'be', 'prevented', 'w', '/', 'tests', '&', 'hpv', 'vaccine', '.', 'vitalsigns'])\n",
      " list(['check', 'out', 'the', 'gci', 'team', \"'s\", 'newest', 'publication', 'on', 'hpv', 'vaccine', 'implementation', 'for', 'cancer', 'prevention', 'in', 'latinamerica', '!'])]\n",
      "[ list(['two', 'uk', 'girls', 'left', 'paralyzed', 'after', 'hpv', 'jabs', '.', 'authorities', 'still', 'claim', 'it', \"'s\", 'coincidence', '.'])\n",
      " list(['cervicalcancer', 'deaths', 'have', 'decreased', 'dramatically', 'over', 'the', 'past', '40', 'years', ',', 'mostly', 'due', 'to', 'increased', 'screening', '.'])]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]]\n",
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_0[:2])\n",
    "print(X_test[:2])\n",
    "print(y_train_0[:2])\n",
    "print(y_test[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save 5% train samples to predication task\n",
    "cut = int(len(X_train_0) * 0.95)\n",
    "X_train = X_train_0[:cut]\n",
    "y_train = y_train_0[:cut]\n",
    "X_pred = X_train_0[cut:]\n",
    "y_pred = y_train_0[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-8b9e755e8c1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mall_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'words'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeling_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-8b9e755e8c1c>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mall_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'words'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeling_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!!!!!do not run this, run the third one below this to directly load the dictionary\n",
    "#create words dictionary for the data\n",
    "from functools import reduce\n",
    "\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "\n",
    "all_tokens = list(reduce(lambda x, y: x + y, [l['words'] for l in modeling_data['data']]))\n",
    "print(all_tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(all_tokens))\n",
    "\n",
    "for token in all_tokens:\n",
    "    frequency[token] += 1\n",
    "    \n",
    "dictionary = sorted(frequency.items(), key=lambda x:x[1], reverse=True)\n",
    "dictionary = [k for k,v in dictionary[:vocab_size]]\n",
    "print(dictionary[:10])\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dict('model/dict.dd', dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':',\n",
       " 'hpv',\n",
       " 'rt',\n",
       " 'vaccine',\n",
       " '.',\n",
       " 'the',\n",
       " ',',\n",
       " 'of',\n",
       " 'to',\n",
       " 'cancer',\n",
       " 'in',\n",
       " 'gardasil',\n",
       " 'for',\n",
       " 'cervicalcancer',\n",
       " 'a',\n",
       " '&',\n",
       " 'and',\n",
       " 'is',\n",
       " '!',\n",
       " 'cervical']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 0\n",
    "dictionary = load_dict('model/dict.dd')\n",
    "if (not vocab_size):\n",
    "    vocab_size = len(dictionary)\n",
    "dictionary[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word to index\n",
    "X_train_f = [[dictionary.index(word) if word in dictionary else -1 for word in doc] for doc in X_train]\n",
    "X_test_f = [[dictionary.index(word) if word in dictionary else -1 for word in doc] for doc in X_test]\n",
    "X_pred_f = [[dictionary.index(word) if word in dictionary else -1 for word in doc] for doc in X_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 0, 46, 781, 22, 74, 100, 121, 7, 13, 35, 55, 352, 54, 40, 162, 15, 1, 3, 4, 1126], [364, 93, 5, 10430, 1019, 20, 1770, 3765, 22, 1, 3, 1637, 12, 9, 61, 10, 8726, 18], [1159, 49, 251, 22, 97, 4382, 12, 448, 3863, 8, 20, 1, 25, 493, 18, 400, 13], [2, 0, 122, 312, 90, 662, 57, 8, 369, 33, 13, 4, 529, 26, 967, 16, 1777, 831, 8, 39, 365, 12, 1], [2, 0, 27, 0, 11, 131, 19, 328, 10, 31, 244, 54, 40, 1, 51]]\n",
      "[[210, 338, 41, 215, 165, 34, 1, 471, 4, 459, 182, 409, 29, 20, 411, 4], [13, 180, 57, 1813, 2238, 296, 5, 1477, 1003, 134, 6, 3875, 616, 8, 448, 67, 4], [2, 0, 27, 0, 14, 262, 7, 346, 362, 10, 14, 509, 110, 118, 250, 34, 168, 1, 3], [726, 12, 8803, 423, 23, 155, 15, 281, 223, 397, 8, 1, 0, 492, 287], [97, 1, 16, 9, 153, 2965, 3326, 3551, 22, 2585, 193, 18, 1077, 125, 8, 159, 0]]\n",
      "[[3, 1413, 264, 41, 177, 1, 68, 32, 757, 37, 697], [2, 0, 4, 84, 981, 18, 11, 3379, 6, 226, 2928, 10352, 1760, 81, 10353, 6, 4817, 19993, 4], [2, 0, 30, 24, 478, 11, 11792, 21], [1, 25, 68, 569, 145, 917, 41, 10, 2948, 1620, 45], [2, 0, 1026, 0, 2602, 1592, 16, 1282, 4158, 7, 19, 9, 422, 33, 1780]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_f[:5])\n",
    "print(X_test_f[:5])\n",
    "print(X_pred_f[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding words using GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 2, 17.012127213987693)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = np.array([len(doc) for doc in X_train_f])\n",
    "(lens.max(), lens.min(), lens.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 39\n",
    "embedding_dim = 50\n",
    "vecs, words, wordidx = load_vectors('twitter.27B.%dd'%(embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_u = sequence.pad_sequences(X_train_f, maxlen=seq_len)\n",
    "X_test_u = sequence.pad_sequences(X_test_f, maxlen=seq_len)\n",
    "X_pred_u = sequence.pad_sequences(X_pred_f, maxlen=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     2     0    46   781    22    74\n",
      "    100   121     7    13    35    55   352    54    40   162    15     1\n",
      "      3     4  1126]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0   364    93     5\n",
      "  10430  1019    20  1770  3765    22     1     3  1637    12     9    61\n",
      "     10  8726    18]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0  1159    49\n",
      "    251    22    97  4382    12   448  3863     8    20     1    25   493\n",
      "     18   400    13]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     2     0   122   312    90   662    57     8\n",
      "    369    33    13     4   529    26   967    16  1777   831     8    39\n",
      "    365    12     1]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      2     0    27     0    11   131    19   328    10    31   244    54\n",
      "     40     1    51]]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0  210  338   41  215  165\n",
      "    34    1  471    4  459  182  409   29   20  411    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   13  180   57 1813 2238  296\n",
      "     5 1477 1003  134    6 3875  616    8  448   67    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    2    0   27    0   14  262    7  346\n",
      "   362   10   14  509  110  118  250   34  168    1    3]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0  726   12 8803  423\n",
      "    23  155   15  281  223  397    8    1    0  492  287]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   97    1   16    9  153 2965\n",
      "  3326 3551   22 2585  193   18 1077  125    8  159    0]]\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     3  1413   264    41   177     1    68    32\n",
      "    757    37   697]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     2     0     4    84\n",
      "    981    18    11  3379     6   226  2928 10352  1760    81 10353     6\n",
      "   4817 19993     4]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     2     0    30    24   478\n",
      "     11 11792    21]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     1    25    68   569   145   917    41    10\n",
      "   2948  1620    45]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      2     0  1026     0  2602  1592    16  1282  4158     7    19     9\n",
      "    422    33  1780]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_u[:5])\n",
    "print(X_test_u[:5])\n",
    "print(X_pred_u[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_embedding(dictionary):\n",
    "    print(vecs.shape)\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "\n",
    "    for i, word in enumerate(dictionary):\n",
    "        #if word:# and re.match(r\"^[a-zA-Z0-9\\-]*$\", word):\n",
    "        src_idx = wordidx[word] if word in wordidx else 0\n",
    "        \n",
    "        if src_idx:\n",
    "            emb[i] = vecs[src_idx]\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "    emb/=3\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1193517, 50)\n"
     ]
    }
   ],
   "source": [
    "embedding = create_embedding(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create NN mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 39, 50)            1165350   \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 39, 50)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 39, 50)            12550     \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 39, 50)            12550     \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 39, 50)            12550     \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 39, 50)            12550     \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 39, 50)            12550     \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 39, 50)            12550     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1950)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 11)                21461     \n",
      "=================================================================\n",
      "Total params: 1,262,111\n",
      "Trainable params: 96,761\n",
      "Non-trainable params: 1,165,350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#pure cnn model\n",
    "dth = 0.5\n",
    "filter_num = 5\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=seq_len, weights=[embedding], trainable=False))\n",
    "model.add(Dropout(dth))\n",
    "\n",
    "#hidden layer\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "# model.add(Dropout(dth))\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "# model.add(Dropout(dth))\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "# model.add(Dropout(dth))\n",
    "\n",
    "#output layer\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(dth))\n",
    "model.add(Dense(modeling_data['categorical_num'], activation='sigmoid'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If a RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batch_input_shape` argument to your first layer.\n- If using the functional API, specify the time dimension by passing a `batch_shape` argument to your Input layer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-fb801956793e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#hidden layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstateful\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    487\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    574\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m    575\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    462\u001b[0m                                for dim in state_size]\n\u001b[0;32m    463\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mreset_states\u001b[1;34m(self, states)\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m             raise ValueError('If a RNN is stateful, it needs to know '\n\u001b[0m\u001b[0;32m    661\u001b[0m                              \u001b[1;34m'its batch size. Specify the batch size '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m                              \u001b[1;34m'of your input tensors: \\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: If a RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batch_input_shape` argument to your first layer.\n- If using the functional API, specify the time dimension by passing a `batch_shape` argument to your Input layer."
     ]
    }
   ],
   "source": [
    "#Bi-LSTM model\n",
    "dth = 0.5\n",
    "filter_num = 5\n",
    "model = Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=seq_len, weights=[embedding], trainable=False, batch_input_shape=(None, 39)))\n",
    "model.add(Dropout(dth))\n",
    "\n",
    "#hidden layers\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "model.add(Bidirectional(LSTM(embedding_dim, stateful=True)))\n",
    "model.add(Dropout(dth))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(modeling_data['categorical_num'], activation='sigmoid'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-4\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model_chk_path = 'model/cnn_hashtagcls_emb{}_weights.validation.h5'.format(embedding_dim)\n",
    "mcp = ModelCheckpoint(model_chk_path, monitor=\"val_loss\", verbose=1,\n",
    "                      save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61597 samples, validate on 16210 samples\n",
      "Epoch 1/100\n",
      "61597/61597 [==============================] - 100s 2ms/step - loss: 2.7711 - acc: 0.6298 - val_loss: 2.4295 - val_acc: 0.6626\n",
      "Epoch 2/100\n",
      "61597/61597 [==============================] - 100s 2ms/step - loss: 2.3289 - acc: 0.6717 - val_loss: 2.2115 - val_acc: 0.6904\n",
      "Epoch 3/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 2.1621 - acc: 0.6868 - val_loss: 2.0366 - val_acc: 0.7059\n",
      "Epoch 4/100\n",
      "61597/61597 [==============================] - 94s 2ms/step - loss: 2.0508 - acc: 0.6970 - val_loss: 1.9585 - val_acc: 0.6648\n",
      "Epoch 5/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.9636 - acc: 0.7073 - val_loss: 1.7907 - val_acc: 0.7018\n",
      "Epoch 6/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.8963 - acc: 0.7178 - val_loss: 1.7763 - val_acc: 0.7316\n",
      "Epoch 7/100\n",
      "61597/61597 [==============================] - 95s 2ms/step - loss: 1.8479 - acc: 0.7239 - val_loss: 1.6903 - val_acc: 0.7200\n",
      "Epoch 8/100\n",
      "61597/61597 [==============================] - 108s 2ms/step - loss: 1.8081 - acc: 0.7277 - val_loss: 1.6789 - val_acc: 0.7030\n",
      "Epoch 9/100\n",
      "61597/61597 [==============================] - 107s 2ms/step - loss: 1.7741 - acc: 0.7324 - val_loss: 1.6260 - val_acc: 0.7181\n",
      "Epoch 10/100\n",
      "61597/61597 [==============================] - 106s 2ms/step - loss: 1.7380 - acc: 0.7365 - val_loss: 1.6342 - val_acc: 0.7196\n",
      "Epoch 11/100\n",
      "61597/61597 [==============================] - 110s 2ms/step - loss: 1.7103 - acc: 0.7395 - val_loss: 1.5794 - val_acc: 0.7338\n",
      "Epoch 12/100\n",
      "61597/61597 [==============================] - 107s 2ms/step - loss: 1.6906 - acc: 0.7417 - val_loss: 1.5728 - val_acc: 0.7079\n",
      "Epoch 13/100\n",
      "61597/61597 [==============================] - 106s 2ms/step - loss: 1.6690 - acc: 0.7409 - val_loss: 1.5584 - val_acc: 0.7353\n",
      "Epoch 14/100\n",
      "61597/61597 [==============================] - 104s 2ms/step - loss: 1.6474 - acc: 0.7464 - val_loss: 1.5347 - val_acc: 0.6951\n",
      "Epoch 15/100\n",
      "61597/61597 [==============================] - 103s 2ms/step - loss: 1.6289 - acc: 0.7452 - val_loss: 1.5097 - val_acc: 0.7367\n",
      "Epoch 16/100\n",
      "61597/61597 [==============================] - 103s 2ms/step - loss: 1.6155 - acc: 0.7477 - val_loss: 1.4992 - val_acc: 0.7444\n",
      "Epoch 17/100\n",
      "61597/61597 [==============================] - 102s 2ms/step - loss: 1.5969 - acc: 0.7487 - val_loss: 1.4960 - val_acc: 0.7439\n",
      "Epoch 18/100\n",
      "61597/61597 [==============================] - 96s 2ms/step - loss: 1.5833 - acc: 0.7510 - val_loss: 1.4726 - val_acc: 0.7287\n",
      "Epoch 19/100\n",
      "61597/61597 [==============================] - 95s 2ms/step - loss: 1.5636 - acc: 0.7498 - val_loss: 1.4689 - val_acc: 0.7539\n",
      "Epoch 20/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.5533 - acc: 0.7521 - val_loss: 1.4603 - val_acc: 0.7419\n",
      "Epoch 21/100\n",
      "61597/61597 [==============================] - 99s 2ms/step - loss: 1.5379 - acc: 0.7519 - val_loss: 1.4311 - val_acc: 0.7338\n",
      "Epoch 22/100\n",
      "61597/61597 [==============================] - 100s 2ms/step - loss: 1.5238 - acc: 0.7536 - val_loss: 1.4189 - val_acc: 0.7464\n",
      "Epoch 23/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.5135 - acc: 0.7535 - val_loss: 1.3946 - val_acc: 0.7298\n",
      "Epoch 24/100\n",
      "61597/61597 [==============================] - 95s 2ms/step - loss: 1.5006 - acc: 0.7555 - val_loss: 1.3922 - val_acc: 0.7436\n",
      "Epoch 25/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.4921 - acc: 0.7546 - val_loss: 1.3619 - val_acc: 0.7466\n",
      "Epoch 26/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.4826 - acc: 0.7554 - val_loss: 1.3883 - val_acc: 0.7552\n",
      "Epoch 27/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.4687 - acc: 0.7565 - val_loss: 1.3591 - val_acc: 0.7440\n",
      "Epoch 28/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.4583 - acc: 0.7563 - val_loss: 1.3575 - val_acc: 0.7510\n",
      "Epoch 29/100\n",
      "61597/61597 [==============================] - 98s 2ms/step - loss: 1.4544 - acc: 0.7583 - val_loss: 1.3645 - val_acc: 0.7602\n",
      "Epoch 30/100\n",
      "61597/61597 [==============================] - 106s 2ms/step - loss: 1.4478 - acc: 0.7593 - val_loss: 1.3528 - val_acc: 0.7534\n",
      "Epoch 31/100\n",
      "61597/61597 [==============================] - 103s 2ms/step - loss: 1.4448 - acc: 0.7588 - val_loss: 1.3511 - val_acc: 0.7475\n",
      "Epoch 32/100\n",
      "61597/61597 [==============================] - 103s 2ms/step - loss: 1.4353 - acc: 0.7580 - val_loss: 1.3404 - val_acc: 0.7507\n",
      "Epoch 33/100\n",
      "61597/61597 [==============================] - 112s 2ms/step - loss: 1.4276 - acc: 0.7606 - val_loss: 1.3309 - val_acc: 0.7505\n",
      "Epoch 34/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.4226 - acc: 0.7570 - val_loss: 1.3310 - val_acc: 0.7632\n",
      "Epoch 35/100\n",
      "61597/61597 [==============================] - 92s 2ms/step - loss: 1.4183 - acc: 0.7580 - val_loss: 1.3322 - val_acc: 0.7484\n",
      "Epoch 36/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.4113 - acc: 0.7606 - val_loss: 1.3192 - val_acc: 0.7513\n",
      "Epoch 37/100\n",
      "61597/61597 [==============================] - 95s 2ms/step - loss: 1.4081 - acc: 0.7626 - val_loss: 1.3174 - val_acc: 0.7628\n",
      "Epoch 38/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.4044 - acc: 0.7628 - val_loss: 1.3208 - val_acc: 0.7576\n",
      "Epoch 39/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.3956 - acc: 0.7602 - val_loss: 1.3133 - val_acc: 0.7489\n",
      "Epoch 40/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.3949 - acc: 0.7608 - val_loss: 1.2981 - val_acc: 0.7587\n",
      "Epoch 41/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.3901 - acc: 0.7628 - val_loss: 1.2975 - val_acc: 0.7526\n",
      "Epoch 42/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.3853 - acc: 0.7621 - val_loss: 1.3080 - val_acc: 0.7574\n",
      "Epoch 43/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.3808 - acc: 0.7635 - val_loss: 1.2961 - val_acc: 0.7622\n",
      "Epoch 44/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.3785 - acc: 0.7639 - val_loss: 1.2939 - val_acc: 0.7721\n",
      "Epoch 45/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.3734 - acc: 0.7608 - val_loss: 1.2939 - val_acc: 0.7621\n",
      "Epoch 46/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.3679 - acc: 0.7618 - val_loss: 1.2914 - val_acc: 0.7632\n",
      "Epoch 47/100\n",
      "61597/61597 [==============================] - 94s 2ms/step - loss: 1.3678 - acc: 0.7624 - val_loss: 1.2951 - val_acc: 0.7606\n",
      "Epoch 48/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.3664 - acc: 0.7643 - val_loss: 1.2881 - val_acc: 0.7572\n",
      "Epoch 49/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.3634 - acc: 0.7609 - val_loss: 1.2800 - val_acc: 0.7662\n",
      "Epoch 50/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.3581 - acc: 0.7638 - val_loss: 1.2748 - val_acc: 0.7658\n",
      "Epoch 51/100\n",
      "61597/61597 [==============================] - 94s 2ms/step - loss: 1.3580 - acc: 0.7604 - val_loss: 1.2763 - val_acc: 0.7525\n",
      "Epoch 52/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.3545 - acc: 0.7621 - val_loss: 1.2909 - val_acc: 0.7440\n",
      "Epoch 53/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.3515 - acc: 0.7624 - val_loss: 1.2684 - val_acc: 0.7656\n",
      "Epoch 54/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.3457 - acc: 0.7642 - val_loss: 1.2741 - val_acc: 0.7671\n",
      "Epoch 55/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.3445 - acc: 0.7621 - val_loss: 1.2779 - val_acc: 0.7569\n",
      "Epoch 56/100\n",
      "61597/61597 [==============================] - 93s 2ms/step - loss: 1.3453 - acc: 0.7606 - val_loss: 1.2739 - val_acc: 0.7674\n",
      "Epoch 57/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.3394 - acc: 0.7599 - val_loss: 1.2619 - val_acc: 0.7715\n",
      "Epoch 58/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.3369 - acc: 0.7630 - val_loss: 1.2673 - val_acc: 0.7854\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.3361 - acc: 0.7622 - val_loss: 1.2648 - val_acc: 0.7746\n",
      "Epoch 60/100\n",
      "61597/61597 [==============================] - 92s 1ms/step - loss: 1.3316 - acc: 0.7644 - val_loss: 1.2572 - val_acc: 0.7695\n",
      "Epoch 61/100\n",
      "61597/61597 [==============================] - 90s 1ms/step - loss: 1.3305 - acc: 0.7627 - val_loss: 1.2651 - val_acc: 0.7716\n",
      "Epoch 62/100\n",
      "61597/61597 [==============================] - 91s 1ms/step - loss: 1.3274 - acc: 0.7604 - val_loss: 1.2609 - val_acc: 0.7484\n",
      "Epoch 63/100\n",
      "61597/61597 [==============================] - 91s 1ms/step - loss: 1.3266 - acc: 0.7616 - val_loss: 1.2601 - val_acc: 0.7682\n",
      "Epoch 64/100\n",
      "61597/61597 [==============================] - 90s 1ms/step - loss: 1.3236 - acc: 0.7627 - val_loss: 1.2742 - val_acc: 0.7711\n",
      "Epoch 65/100\n",
      "61597/61597 [==============================] - 90s 1ms/step - loss: 1.3207 - acc: 0.7639 - val_loss: 1.2605 - val_acc: 0.7770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d234a2b5f8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick test\n",
    "model.fit(X_train_u, y_train, validation_data=(X_test_u, y_test), epochs=100, batch_size=64,  callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best result\n",
    "- 0.8353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### current best model snapshot:\n",
    "\n",
    "```python\n",
    "dth = 0.5\n",
    "filter_num = 5\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=seq_len, weights=[embedding], trainable=False))\n",
    "\n",
    "#hidden layer\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "model.add(Dropout(dth))\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "model.add(Dropout(dth))\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "model.add(Conv1D(embedding_dim, filter_num, padding='same', activation='relu'))\n",
    "model.add(Dropout(dth))\n",
    "\n",
    "#output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(modeling_data['categorical_num'], activation='sigmoid'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable=True\n",
    "model.optimizer.lr=1e-4\n",
    "model.fit(X_train_u, y_train, validation_data=(X_test_u, y_test), epochs=100, batch_size=64, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and save model for future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save_weights('model/cnn_hashtagcls_emb{}_weights.h5'.format(embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine train and test data and retrain the model as the final model to use for predication\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "model.fit(\n",
    "    np.concatenate((X_train_u, y_train), axis=0),\n",
    "    np.concatenate((X_test_u, y_test), axis=0),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping])\n",
    "model.save_weights(\n",
    "    \"model/all_cnn_hashtagcls_emb{}_weights.h5\".format(embedding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract the last hidden layer information\n",
    ">https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predication\n",
    "**The predication will be performed on both no_labeled data set and neg_sample and pred set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load two data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "with open(\"temp/neg_sample_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    neg_sample = json.load(f)\n",
    "    \n",
    "with open(\"temp/no_labeled_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    nolabel_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_pred_u)\n",
    "print(len(X_pred_u))\n",
    "print(len(y_pred))\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
